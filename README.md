# ğŸ¯ Resume Customizer Pro

A comprehensive resume customization platform with advanced multi-user features, smart email automation, team collaboration, and high-performance architecture.

## ğŸ” Security Features

- **Password Encryption**: AES-256 encryption for email passwords
- **Secure Authentication**: PBKDF2 password hashing
- **Input Validation**: Comprehensive input sanitization
- **Rate Limiting**: Protection against brute force attacks
- **Session Management**: Secure session handling
- **Access Control**: Role-based permissions system

## ğŸš€ Deployment

### Database (Neon.tech)

1. Create a free account on [Neon.tech](https://neon.tech)
2. Create a new project
3. Get your database connection string
4. Set up the environment variables as described in `.env.example`

### Installation

The project uses a modular requirements structure for different environments:

1. **Basic Installation** (Production):

   ```bash
   pip install -r requirements.txt -r requirements-base.txt
   ```

2. **Development Setup** (includes testing tools):

   ```bash
   pip install -r requirements.txt -r requirements-base.txt -r requirements-dev.txt
   ```

3. **Windows Development** (includes Windows-specific packages):
   ```bash
   pip install -r requirements.txt -r requirements-base.txt -r requirements-windows.txt
   ```

### Application Deployment (Render.com)

1. Fork this repository to your GitHub account
2. Create a new Web Service on [Render.com](https://render.com)
3. Connect your GitHub repository
4. The deployment configuration is already set up in `render.yaml`
5. Set up your environment variables in the Render dashboarder Pro - Enterprise Multi-User Platform

A comprehensive resume customization platform with advanced multi-user features, smart email automation, team collaboration, and high-performance architecture supporting 50+ concurâ””â”€â”€ ğŸ“ resume_customizer/ # Core resume customization logic
â”‚ â”œâ”€â”€ **init**.py
â”‚ â”œâ”€â”€ analyzers/ # Analysis modules
â”‚ â”œâ”€â”€ parsers/ # Text and document parsing
â”‚ â”œâ”€â”€ processors/ # Document processing
â”‚ â””â”€â”€ formatters/ # Formatting modules
â”‚.

## ğŸ” Security Features

- **Password Encryption**: AES-256 encryption for email passwords
- **Secure Authentication**: PBKDF2 password hashing
- **Input Validation**: Comprehensive input sanitization
- **Rate Limiting**: Protection against brute force attacks
- **Session Management**: Secure session handling
- **Access Control**: Role-based permissions system

## ğŸ“Š Database Features

- **High-Performance PostgreSQL**: Optimized for concurrent access
- **Adaptive Connection Pooling**: Dynamic pool sizing based on load metrics
- **Encrypted Connection Strings**: Secure storage of database credentials
- **Query Monitoring**: Automatic detection and logging of slow queries
- **Read/Write Splitting**: Separate connection pools for read and write operations
- **Repository Pattern**: Standardized data access with error handling
- **Query Builder**: Fluent interface for building complex SQL queries
- **Sharding Strategy**: Horizontal scaling for future data growth
- **Role-Based Access Control**: Fine-grained database permissions
- **Automatic Migrations**: Database versioning and migrations
- **Data Validation**: Schema-level constraints and validation
- **Backup & Recovery**: Automated backup procedures

## âœ¨ Enhanced Features

### ğŸ‘¤ User Account Management

- **Secure Authentication**: PBKDF2 password hashing, session management
- **User Profiles**: Bio, skills, professional information, profile pictures
- **Subscription Tiers**: Free, Premium, Enterprise with usage limits
- **Analytics Dashboard**: Usage tracking, performance metrics

### ğŸ“§ Smart Email Follow-up System

- **Advanced Templates**: Professional, Casual, Creative styles
- **Smart Scheduling**: Business hours optimization, timezone awareness
- **Email Tracking**: Opens, clicks, replies with analytics
- **Campaign Management**: Multi-sequence follow-ups, auto-stop on reply
- **Company Intelligence**: Personalized content based on company research

### ğŸ‘¥ Multi-User Collaboration

- **Team Workspaces**: Create and manage teams with role-based access
- **Resume Sharing**: Share with users, teams, or public links
- **Real-time Comments**: Collaborative feedback system
- **Permission Levels**: View, Comment, Edit access controls
- **Activity Feeds**: Track team activity and notifications

### âš¡ High-Performance Architecture

- **PostgreSQL Database**: Optimized for enterprise scale
- **Database Pooling**: Connection pool for optimal performance
- **Advanced Caching**: Memory cache with TTL, file processing cache
- **Async Operations**: Non-blocking background processing
- **Error Handling**: Comprehensive error recovery and logging

### ğŸ“„ Enhanced Resume Processing

- **Batch Processing**: Parallel processing with worker pools
- **Format Preservation**: Maintains original formatting and styles
- **Version Control**: Track resume versions and changes
- **Template System**: Save and reuse resume templates
- **Intelligent Point Distribution**: Sophisticated algorithm for optimal tech stack distribution
- **Customizable Formatting Rules**: Configuration system for bullet points and formatting styles
- **Enhanced Preview Feature**: Multi-view preview with before/after comparison and visual diff

## ğŸš€ Quick Start

### Option 1: Local Development

```bash
# Clone the repository
git clone https://github.com/12shivam219/Injector.git
cd Injector

# Install core dependencies
pip install -r requirements.txt

# Install Google Drive integration (optional)
pip install -r requirements-gdrive.txt

# Run the application
streamlit run app.py
```

### Option 2: One-Click Deploy

- **Streamlit Cloud**: [![Deploy to Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io)
- **Railway**: Deploy directly from GitHub
- **Heroku**: One-click deploy with Heroku button

## ï¿½ Installation & Setup

### Requirements

- Python 3.13+
- PostgreSQL 15+
- Redis (optional, for task queue)

### Installation Options

1. **Basic Installation** (Production):

   ```bash
   pip install -r requirements.txt -r requirements-base.txt
   ```

2. **Development Setup**:

   ```bash
   pip install -r requirements.txt -r requirements-base.txt -r requirements-dev.txt
   ```

3. **Windows Development**:
   ```bash
   pip install -r requirements.txt -r requirements-base.txt -r requirements-windows.txt
   ```

## ğŸ”§ Usage

### 1. Format Management (First Step)

- Go to the **Format Manager** tab first
- Upload sample resume templates that represent different formats
- Name and describe each format for easy reference
- System will analyze and store format patterns
- Test format matching with sample resumes

### 2. Upload Resumes

- Upload one or more DOCX files
- System will automatically match with stored formats
- Each resume should have clear project sections with "Responsibilities:" headings

### 2. Add Tech Stacks

For each resume, provide tech stacks in this format:

```
Python: â€¢ Developed web applications using Django and Flask â€¢ Implemented RESTful APIs
JavaScript: â€¢ Created interactive UI components with React â€¢ Utilized Node.js for backend services
AWS: â€¢ Deployed applications using EC2 and S3 â€¢ Managed databases with RDS
```

### 3. Configure Email (Optional)

- **Recipient Email**: Where to send the resume
- **Sender Email**: Your email address
- **App Password**: Use app-specific passwords for Gmail/Office365
- **SMTP Server**: Pre-configured options available

### 4. Preview Changes

- Click "ğŸ” Preview Changes" to see exactly what will be modified
- Multiple preview views:
  - Full Preview: Complete resume with highlighted changes
  - New Points Only: View only the additions by project
  - Visual Diff: Color-coded visualization of changes
  - Before/After: Side-by-side comparison
- Detailed distribution statistics showing points per project

### 5. Generate & Send

- **Individual**: Process one resume at a time
- **Bulk Mode**: Process 3+ resumes simultaneously for maximum speed

## ğŸ—ï¸ Architecture

### Core Components

- **Resume Parser**: Finds projects and responsibilities sections
- **Point Distributor**: Intelligent algorithm for optimal tech stack distribution
- **Format Preserver**: Maintains original document formatting
- **Formatting Configuration**: Customizable bullet points and formatting styles
- **Enhanced Preview**: Multi-view preview with visual diff and comparison
- **Email Manager**: SMTP connection pooling and batch sending
- **Parallel Processor**: Multi-threaded resume processing

### Performance Features

- **Connection Pooling**: Reuses SMTP connections for faster email sending
- **Parallel Processing**: Up to 8x faster with multiple workers
- **Memory Optimization**: Efficient buffer management
- **Real-time Progress**: Live updates during bulk operations

## ğŸ“ Project Structure

## ğŸ“ Project Structure

```
injector/
â”œâ”€â”€ app.py                  # Main Streamlit application
â”œâ”€â”€ config.py              # Configuration module
â”œâ”€â”€ requirements.txt       # Main requirements file
â”œâ”€â”€ requirements-base.txt  # Core dependencies
â”œâ”€â”€ requirements-dev.txt   # Development tools
â”œâ”€â”€ requirements-windows.txt # Windows-specific packages
â”‚
â”œâ”€â”€ ğŸ“ core/              # Core application logic
â”‚   â”œâ”€â”€ config.py         # Core configuration
â”‚   â”œâ”€â”€ constants.py      # Global constants
â”‚   â”œâ”€â”€ errors.py         # Error definitions
â”‚   â””â”€â”€ types.py         # Type definitions
â”‚
â”œâ”€â”€ ğŸ“ database/          # Database components
â”‚   â”œâ”€â”€ adaptive_pool.py  # Connection pooling
â”‚   â”œâ”€â”€ encryption.py     # Data encryption
â”‚   â”œâ”€â”€ session.py       # Session management
â”‚   â”œâ”€â”€ models/          # Database models
â”‚   â””â”€â”€ repository/      # Data access layer
â”‚
â”œâ”€â”€ ğŸ“ resume_customizer/ # Core resume logic
â”‚   â”œâ”€â”€ analyzers/       # Analysis modules
â”‚   â”œâ”€â”€ parsers/         # Document parsing
â”‚   â”œâ”€â”€ processors/      # Processing logic
â”‚   â””â”€â”€ formatters/      # Output formatting
â”‚
â”œâ”€â”€ ğŸ“ pages/            # Streamlit pages
â”œâ”€â”€ ğŸ“ scripts/          # Utility scripts
â”œâ”€â”€ ğŸ“ tests/            # Test suite
â””â”€â”€ ğŸ“ docs/             # Documentation
â”‚   â”œâ”€â”€ celeryconfig.py             # Celery configuration
â”‚   â”œâ”€â”€ docker-compose.prod.yml     # Production Docker setup
â”‚   â”œâ”€â”€ pytest.ini                 # Test configuration
â”‚   â””â”€â”€ celery.exchange             # Celery queue configuration
â”‚
â”œâ”€â”€ ğŸ“ core/                        # Core application modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ resume_processor.py         # Resume processing coordination
â”‚   â”œâ”€â”€ email_handler.py            # Email operations module
â”‚   â”œâ”€â”€ document_processor.py       # Document processing module
â”‚   â”œâ”€â”€ text_parser.py              # Text parsing functionality
â”‚   â”œâ”€â”€ async_processor.py          # Async processing
â”‚   â””â”€â”€ async_integration.py        # Async integration
â”‚
â”œâ”€â”€ ğŸ“ enhancements/                # Enhanced feature modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics_analytics_enhanced.py
â”‚   â”œâ”€â”€ health_monitor_enhanced.py
â”‚   â”œâ”€â”€ email_templates_enhanced.py
â”‚   â”œâ”€â”€ enhanced_error_recovery.py
â”‚   â”œâ”€â”€ batch_processor_enhanced.py
â”‚   â”œâ”€â”€ progress_tracker_enhanced.py
â”‚   â””â”€â”€ error_handling_enhanced.py
â”‚
â”œâ”€â”€ ğŸ“ infrastructure/              # Infrastructure components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app/                        # Application bootstrap
â”‚   â”œâ”€â”€ monitoring/                 # Monitoring and logging
â”‚   â”œâ”€â”€ error_handling/            # Error handling
â”‚   â”œâ”€â”€ security/                  # Security components
â”‚   â”œâ”€â”€ utilities/                 # Shared utilities
â”‚   â””â”€â”€ async_processing/          # Async operations
â”‚
â”œâ”€â”€ ğŸ“ utilities/                   # Helper utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ validators.py
â”‚   â”œâ”€â”€ memory_optimizer.py
â”‚   â”œâ”€â”€ structured_logger.py
â”‚   â”œâ”€â”€ lazy_imports.py
â”‚   â””â”€â”€ retry_handler.py
â”‚
â”œâ”€â”€ ğŸ“ config/                       # Configuration files
â”‚   â””â”€â”€ formatting_config.json       # Formatting rules configuration
â”‚
â”œâ”€â”€ ğŸ“ database/                    # Database modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ connection.py
â”‚   â”œâ”€â”€ migrations.py
â”‚   â”œâ”€â”€ migrate_from_json.py
â”‚   â””â”€â”€ requirements_manager_db.py
â”‚
â”œâ”€â”€ ğŸ“ ui/                          # User interface components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ components.py
â”‚   â”œâ”€â”€ bulk_processor.py
â”‚   â”œâ”€â”€ resume_tab_handler.py
â”‚   â”œâ”€â”€ requirements_manager.py
â”‚   â”œâ”€â”€ secure_components.py
â”‚   â”œâ”€â”€ gdrive_picker.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ ğŸ“ processors/                  # Document processors
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ point_distributor.py
â”‚
â”œâ”€â”€ ğŸ“ templates/                   # Resume templates
â”‚   â”œâ”€â”€ software_engineer_template.txt
â”‚   â”œâ”€â”€ data_science_template.txt
â”‚   â”œâ”€â”€ product_manager_template.txt
â”‚   â”œâ”€â”€ executive_template.txt
â”‚   â””â”€â”€ general_professional_template.txt
â”œâ”€â”€ ğŸ“ tests/                       # Test files
â”‚   â”œâ”€â”€ test_comprehensive.py
â”‚   â”œâ”€â”€ test_bullet_formatting.py
â”‚   â”œâ”€â”€ test_celery_end_to_end.py
â”‚   â”œâ”€â”€ test_celery_task.py
â”‚   â”œâ”€â”€ test_imports.py
â”‚   â”œâ”€â”€ test_real_task.py
â”‚   â”œâ”€â”€ test_security_phase1.py
â”‚   â””â”€â”€ performance_benchmark.py
â”‚
â”œâ”€â”€ ğŸ“ scripts/                     # Deployment & utility scripts
â”‚   â”œâ”€â”€ run_worker.bat              # Windows Celery worker script
â”‚   â”œâ”€â”€ start_celery.bat           # Windows Celery startup
â”‚   â”œâ”€â”€ start_celery_worker.py     # Python Celery worker
â”‚   â””â”€â”€ setup_database.py          # Database setup script
â”‚
â”œâ”€â”€ ğŸ“ docs/                        # Documentation
â”‚   â”œâ”€â”€ DATABASE_MIGRATION_GUIDE.md
â”‚   â”œâ”€â”€ ENHANCEMENT_SUMMARY.md
â”‚   â”œâ”€â”€ PHASE1_USAGE_GUIDE.md
â”‚   â”œâ”€â”€ README-celery.md
â”‚   â”œâ”€â”€ README-monitoring.md
â”‚   â””â”€â”€ REQUIREMENTS_UPDATE_SUMMARY.md
â”‚
â””â”€â”€ ğŸ“ .streamlit/                  # Streamlit configuration
    â””â”€â”€ config.toml
```

## ï¿½ Encryption Keys

- **Generate keys**: Run `python scripts/generate_keys.py` to produce two Fernet keys.
- **Local development**: Copy the generated values into a local `.env` file (this repo now includes an example `.env.example`).
- **Production**: Do NOT commit real keys. Use your deployment platform's secret manager (Streamlit secrets, Vault, environment variables) to set `DB_ENCRYPTION_KEY` and `USER_DATA_ENCRYPTION_KEY`.
- **Streamlit Cloud**: Add keys to Streamlit secrets and they will be loaded by `infrastructure/app/streamlit_config.py`.

## ï¿½ğŸ”’ Security

- **No Credential Storage**: Email credentials are never stored
- **App-Specific Passwords**: Supports secure authentication methods
- **Input Validation**: Validates file types and content
- **Error Handling**: Graceful handling of failures

## ğŸš€ Deployment

### Recommended Platforms

1. **Streamlit Cloud** (Free)

   - Best for: Quick deployment, public projects
   - Setup: Connect GitHub â†’ Deploy
   - URL: Auto-generated

2. **Railway** (Modern PaaS)
   - Best for: Modern deployment, generous free tier
   - Setup: Connect GitHub â†’ Auto-deploy
   - Features: Automatic HTTPS, custom domains

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.

## âš¡ Performance

### Benchmarks

- **Single Resume**: ~2-3 seconds
- **Bulk Processing**: Up to 8x faster with parallel workers
- **Email Sending**: Connection pooling for optimal speed
- **Memory Usage**: Optimized for multiple file processing

### Scaling

- **Concurrent Users**: Supports multiple simultaneous users
- **File Size**: Handles large DOCX files efficiently
- **Batch Size**: Configurable worker count and batch sizes

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **Email Not Sending**

   - Use app-specific passwords
   - Check firewall settings
   - Verify SMTP server settings

2. **Resume Not Recognized**

   - Ensure clear "Responsibilities:" sections
   - Check project heading formats
   - Verify DOCX format

3. **Performance Issues**
   - Reduce worker count for lower-spec machines
   - Check memory availability
   - Optimize batch sizes

### Debug Mode

Enable debug output:

```python
import streamlit as st
st.write("Debug info:", st.session_state)
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- ğŸ“– [Deployment Guide](DEPLOYMENT.md)
- ğŸ› [Report Issues](https://github.com/12shivam219/Injector/issues)
- ğŸ’¬ [Discussions](https://github.com/12shivam219/Injector/discussions)

## ğŸ¯ Use Cases

- **Job Seekers**: Customize resumes for different job applications
- **Recruiters**: Bulk process candidate resumes
- **Career Services**: Help students tailor resumes
- **Freelancers**: Quick resume customization for clients

## ğŸŒŸ Key Benefits

- â±ï¸ **Time Saving**: Bulk process multiple resumes
- ğŸ¯ **Targeted**: Focus on top 3 projects for impact
- ğŸ“§ **Automated**: Direct email sending capabilities
- ğŸ” **Preview**: See changes before processing
- ğŸš€ **Fast**: Parallel processing for speed
- ğŸ“± **User-Friendly**: Intuitive Streamlit interface

---

**Made with â¤ï¸ using Streamlit**

_Perfect for job applications, recruitment agencies, and career services!_
